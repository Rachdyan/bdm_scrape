name: Scrape RT Mac Firefox
on:
  schedule:
    # At 8:30 PM Jakarta Time (08:45 UTC)
    - cron: '00 13 * * 1-5'
  workflow_dispatch:
#  // push:
#     branches: [ master ]
#   pull_request:
#     branches:
#   workflow_dispatch:
#     branches:

jobs:
  build:

    env:
      PYTHONIOENCODING: "utf-8"
      PY_COLORS: "1"
    strategy:
      fail-fast: false
      max-parallel: 1
      matrix:
        os: [macos-latest]
        python-version: ["3.13"]

    runs-on: ${{ matrix.os }}
    steps:
    - uses: actions/checkout@v4
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ matrix.python-version }}
    - name: Set Locale
      if: runner.os == 'Linux'
      run: |
        sudo apt-get install tzdata locales -y && sudo locale-gen en_US.UTF-8
        sudo localectl set-locale LANG="en_US.UTF-8"
        export LANG="en_US.UTF-8"
        sudo update-locale
        locale -a
        locale
        locale -c -k LC_NUMERIC
        localectl status
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install --upgrade pip
        pip install --upgrade wheel
        pip install -r requirements2.txt
        pip install --upgrade pyautogui
    - name: Install extra dependencies
      if: runner.os == 'Linux'
      run: |
        pip install --upgrade python-xlib
    # - name: Lint with flake8
    #   run: |
    #     pip install flake8
    #     # Stop the build if there are flake8 issues
    #     flake8 . --count --show-source --statistics --exclude=temp
    - name: Install Firefox
      if: matrix.os == 'ubuntu-22.04'
      run: |
        sudo apt update
        sudo apt install -y firefox
    - name: Check the console scripts interface
      run: |
        seleniumbase
        sbase
    - name: Install geckodriver
      run: |
        seleniumbase install geckodriver
    - name: Make sure pytest is working
      run: |
        echo "def test_1(): pass" > nothing.py
        pytest nothing.py --uc
    - name: Check which Firefox binaries exist
      run: |
        python -c "import os; print(os.path.exists('/usr/bin/firefox'))"
        python -c "import os; print(os.path.exists('/bin/firefox'))"
    - name: Display Firefox binary that's used
      run: |
        python -c "from seleniumbase.core import detect_b_ver; print(detect_b_ver.get_binary_location('firefox'))"
        python -c "from seleniumbase import undetected; print(undetected.find_firefox_executable())"
    - name: Make sure pytest with sb is working
      run: |
        echo "def test_0(sb): pass" > verify_sb.py
        pytest verify_sb.py
    - name: Run python scrape_rt_firefox.py --debug with retry
      env:
        PROXY_USER: ${{ secrets.PROXY_USER }}
        PROXY_PASSWORD: ${{ secrets.PROXY_PASSWORD }}
        PROXY_HOST: ${{ secrets.PROXY_HOST }}
        PROXY_PORT: ${{ secrets.PROXY_PORT }}
        BOT_TOKEN: ${{ secrets.BOT_TOKEN }}
        WEBSITE: ${{ secrets.WEBSITE }}
        SITE_EMAIL: ${{ secrets.SITE_EMAIL }}
        SITE_PASSWORD: ${{ secrets.SITE_PASSWORD }}
        STOCK_WEBSITE: ${{ secrets.STOCK_WEBSITE }}
        SA_PRIVKEY_ID: ${{ secrets.SA_PRIVKEY_ID }}
        SA_PRIVKEY: ${{ secrets.SA_PRIVKEY }}
        SA_CLIENTMAIL: ${{ secrets.SA_CLIENTMAIL }}
        SA_CLIENT_X509_URL: ${{ secrets.SA_CLIENT_X509_URL }}
        CAPTCHA_KEY: ${{ secrets.CAPTCHA_KEY }}
        SB_WEBSITE: ${{ secrets.SB_WEBSITE }}
        SB_USER: ${{ secrets.SB_USER }}
        SB_PASSWORD: ${{ secrets.SB_PASSWORD }}
        EMAIL_ACCOUNT: ${{ secrets.EMAIL_ACCOUNT }}
        EMAIL_PASSWORD: ${{ secrets.EMAIL_PASSWORD }}
      run: |
        max_attempts=3
        attempt=1
        success=false
        
        echo "Starting scraping process with retry logic (max attempts: $max_attempts)"
        
        while [ $attempt -le $max_attempts ] && [ $success = false ]; do
          echo "Attempt $attempt of $max_attempts"
          
          # Create a log file for this attempt
          log_file="scrape_attempt_${attempt}.log"
          
          # Run the script and capture output and exit code
          python scrape_rt_firefox.py --debug 2>&1 | tee $log_file
          exit_code=${PIPESTATUS[0]}
          
          # Check if the script succeeded
          if [ $exit_code -eq 0 ]; then
            echo "Script completed successfully on attempt $attempt"
            success=true
          else
            echo "Script failed on attempt $attempt with exit code $exit_code"
            
            if [ $attempt -lt $max_attempts ]; then
              echo "Waiting 30 seconds before retrying..."
              sleep 30
              
              # Check for common error patterns in the log
              if grep -q "Authorization header not found" $log_file; then
                echo "Error detected: Authorization header not found"
              elif grep -q "Error in captcha solving" $log_file; then
                echo "Error detected: Captcha solving failed"
              elif grep -q "No matching images" $log_file; then
                echo "Error detected: No matching images in captcha"
              elif grep -q "Google Sheets API Error" $log_file; then
                echo "Error detected: Google Sheets API error"
              elif grep -q "Still not logged in" $log_file; then
                echo "Error detected: Login failed"
              elif grep -q "Network error\|Connection error\|Timeout" $log_file; then
                echo "Error detected: Network/Connection issue"
              else
                echo "Unknown error occurred, check the log file for details"
              fi
            else
              echo "Maximum retry attempts ($max_attempts) reached. Giving up."
              echo "Last attempt log file: $log_file"
              
              # Upload all log files as artifacts for debugging
              echo "Uploading log files for debugging..."
            fi
          fi
          
          attempt=$((attempt + 1))
        done
        
        # Exit with the appropriate status
        if [ $success = true ]; then
          echo "Scraping completed successfully!"
          # Clean up log files on success
          rm -f scrape_attempt_*.log
          exit 0
        else
          echo "Scraping failed after $max_attempts attempts"
          exit 1
        fi